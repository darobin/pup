[=context=]<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <script src="https://www.w3.org/Tools/respec/respec-w3c" async class="remove"></script>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%220.9em%22 font-size=%22105%22>üê∂</text></svg>">
    <title>Principles of User Privacy (PUP)</title>
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@robinberjon">
    <meta name="twitter:creator" content="@robinberjon">
    <meta name="twitter:title" property="og:title" content="Principles of User Privacy (PUP)">
    <meta name="twitter:description" property="og:description" content="Setting the standard for a robust, policy-ready understanding of privacy.">
    <meta name="twitter:image" property="og:image" content="https://darobin.github.io/pup/pup.png">
    <meta name="twitter:image:alt" content="A cute puppy face drawing">
    <meta name="twitter:url" property="og:url" content="https://darobin.github.io/pup/">
    <meta property="og:locale" content="en">
    <style>
      body {
        background: url(proposal.svg) no-repeat fixed !important;
        background-size: 25px 380px !important;
      }
    </style>
    <script class="remove">
      var respecConfig = {
        specStatus: 'unofficial',
        postProcess: [(config, doc) => {
          let time = doc.querySelector('.head h2 time')
            , h2 = doc.querySelector('.head h2')
          ;
          h2.innerHTML = 'Proposal ';
          h2.appendChild(time);
        }],
        editors: [{
          name: 'Robin Berjon',
          company: 'The New York Times',
          companyURL: 'https://nytimes.com/',
          url: 'https://berjon.com/',
        }],
        github: 'https://github.com/darobin/pup',
        edDraftURI: 'https://darobin.github.io/pup/',
        shortName: 'pup',
        localBiblio: {
          'ANTI-TRACKING-POLICY': {
            title: 'Anti-Tracking Policy',
            href: 'https://wiki.mozilla.org/Security/Anti_tracking_policy#Tracking_Definition',
            publisher: 'Mozilla',
          },
          'BIT-BY-BIT': {
            title: 'Bit By Bit: Social Research in the Digital Age',
            href: 'https://www.bitbybitbook.com/',
            authors: ['Matt Salganik'],
            publisher: 'Princeton University Press',
            status: 'You can read this book free of charge, but Matt is an outstanding author and I encourage you to support him by buying his book!',
          },
          'CONFIDING': {
            title: 'Confiding in Con Men: U.S. Privacy Law, the GDPR, and Information Fiduciaries',
            authors: ['Lindsey Barrett'],
            href: 'https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3354129',
          },
          'EUROBAROMETER-443': {
            title: 'Eurobarometer 443: e-Privacy',
            authors: ['European Commission'],
            href: 'https://ec.europa.eu/COMMFrontOffice/publicopinion/index.cfm/Survey/getSurveyDetail/instruments/FLASH/surveyKy/2124',
          },
          'FIP': {
            title: 'Fair Information Practices: A Basic History',
            href: 'http://bobgellman.com/rg-docs/rg-FIPShistory.pdf',
            authors: ['Bob Gellman'],
            status: '(PDF)',
          },
          'GDPR': {
            title: 'General Data Protection Regulations (GDPR) / Regulation (EU) 2016/679',
            href: 'https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32016R0679&from=EN',
            authors: ['European Parliament and Council of European Union'],
          },
          'GPC': {
            title: 'Global Privacy Control (GPC)',
            authors: ['Robin Berjon', 'Sebastian Zimmeck', 'Ashkan Soltani', 'David Harbage', 'Peter Snyder'],
            href: 'https://globalprivacycontrol.github.io/gpc-spec/',
            publisher: 'W3C',
          },
          'NYT-PRIVACY': {
            title: 'How The New York Times Thinks About Your Privacy',
            author: ['Robin Berjon'],
            href: 'https://open.nytimes.com/how-the-new-york-times-thinks-about-your-privacy-bc07d2171531',
            publisher: 'NYT Open',
          },
          'PBD': {
            title: 'Privacy by Design',
            href: 'https://conversationalist.org/2019/09/13/feminism-explains-our-toxic-relationships-with-our-smartphones/',
            publisher: 'Office of the Information and Privacy Commissioner, Ontario',
          },
          'PHONE-ON-FEMINISM': {
            title: 'This is your phone on feminism',
            href: 'https://conversationalist.org/2019/09/13/feminism-explains-our-toxic-relationships-with-our-smartphones/',
            authors: ['Maria Farrell'],
            publisher: 'The Conversationalist',
            rawDate: '2019-09-13',
          },
          'PRIVACY-CONTESTED': {
            title: 'Privacy is an essentially contested concept: a multi-dimensional analytic for mapping privacy',
            authors: ['Deirdre K. Mulligan', 'Colin Koopman', 'Nick Doty'],
            href: 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5124066/',
            publisher: 'Philosophical Transacions A',
          },
          'PRIVACY-IN-CONTEXT': {
            title: 'Privacy in Context',
            authors: ['Helen Nissenbaum'],
            href: 'https://www.sup.org/books/title/?id=8862',
            publisher: 'SUP',
          },
          'PRIVACY-IS-POWER': {
            title: 'Privacy Is Power',
            authors: ['Carissa V√©liz'],
            href: 'https://www.penguin.com.au/books/privacy-is-power-9781787634046',
            publisher: 'Bantam Press',
          },
          'PRIVACY-PROJECT': {
            title: 'The Privacy Project',
            href: 'https://www.nytimes.com/interactive/2019/opinion/internet-privacy-project.html',
            publisher: 'The New York Times',
          },
          'PRIVACY-THREAT': {
            title: 'Target Privacy Threat Model',
            href: 'https://w3cping.github.io/privacy-threat-model/',
            authors: ['Jeffrey Yasskin', 'Tom Lowenthal'],
            publisher: 'W3C PING',
          },
          'SURVEILLANCE-CAPITALISM': {
            title: 'The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power',
            authors: ['Shoshana Zuboff'],
            href: 'https://www.publicaffairsbooks.com/titles/shoshana-zuboff/the-age-of-surveillance-capitalism/9781610395694/',
            publisher: 'Hachette Public Affairs',
          },
          'TRACKING-PREVENTION-POLICY': {
            title: 'Tracking Prevention Policy',
            href: 'https://webkit.org/tracking-prevention-policy/',
            publisher: 'Apple',
          },
          'W3C-PROCESS': {
            title: 'W3C Process Document',
            authors: ['Elika J. Etemad / fantasai', 'Florian Rivoal'],
            href: 'https://www.w3.org/Consortium/Process/',
            publisher: 'W3C',
          },
        },
      };
    </script>
  </head>
  <body>
    <section id="abstract">
      <p>
        Privacy is an essentially contested concept [[?PRIVACY-CONTESTED]]. Its debated meaning
        render its support problematic in the context of a standards-setting process grounded in
        consensus [[?W3C-PROCESS]], in seeking out technical solutions grounded on shared
        requirements, and in addressing the needs of a worldwide constituency. This document
        provides definitions for privacy and related concepts that are suitable for a global
        audience, that can ground a methodology for privacy threat modelling, and can guide the
        development of the Web as a trustworthy platform. In the spirit of building a much-needed
        bridge between technology and policy, this document is written under the expectation that
        it can apply to both.
      </p>
    </section>
    <section id="sotd"></section>
    <section>
      <h2>Introduction</h2>
      <p>
        Privacy is essential to trust, and trust is a cornerstone value of the Web [[?RFC8890]].
        In much of everyday life, people have little difficulty assessing whether a given flow of
        information constitutes a violation of privacy or not [[?NYT-PRIVACY]]. However, in the digital
        space, users struggle to understand how their data may flow between contexts and how such
        flows may affect them, not just immediately but at a much later time and in completely
        different situations. Some actors then seize upon this confusion in order to extract and
        exploit personal data at unprecedented scale.
      </p>
      <p>
        The goal of this document is to define all the terms that may prove useful in developing
        technology and policy that relate to privacy and personal data. It additionally provides
        several frameworks that address the common need that is privacy threat modelling, the
        frequent debate over consent, and the under-developed set of issues in privacy that are of a
        collective, relational nature.
      </p>
    </section>
    <!--
      XXX
      - examples with Poodle (because PUP), so Poodle Naps, Poodle Fetch, PNail Salon, AIBO.
    -->
    <section>
      <h2>Definitions</h2>
      <p>
        This section provides a number of elementary building blocks from which to establish a
        shared understanding of privacy. A significant portion of the definitions below build atop
        the discontinued work in <em>Tracking Preference Expression (DNT)</em> [[tracking-dnt]].
      </p>
      <section>
        <h2>People &amp; Data</h2>
        <p>
          A <dfn>user</dfn> (also <dfn>person</dfn> or <dfn>data subject</dfn>) is any natural
          person.
        </p>
        <p>
          We define <dfn>personal data</dfn> as any information relating to a [=person=] such
          that:
        </p>
        <ul>
          <li>
            this [=person=] is identified, directly or indirectly, by reference to an
            identifier such as a name, email address, an arbitrary identifier or identification
            number, an online identifier such as an IP address or any identifier attached to a
            device this [=person=] may be using, phone number, location data, or factors specific
            to the physical, physiological, genetic, mental, economic, cultural, or social identity
            of that [=person=], as well as identifiers derived from such data, for instance
            through hashing; or
          </li>
          <li>
            this [=person=] could reasonably be reidentified from a conjunction of this data with
            other data; or
          </li>
          <li>
            the data pertains to a group of people such that a [=person=] may find themselves to
            be the subject of a treatment related to this group, even if the entity carrying out the
            treatment has no way to identify that [=person=].
          </li>
        </ul>
        <p>
          Data is <dfn>permanently de-identified</dfn> when there exists a high level of confidence
          that no human subject of the data can be identified, directly or indirectly (e.g., via
          association with an identifier, user agent, or device), by that data alone or in
          combination with other retained or available information, including as being part of a
          group. Note that further considerations relating to groups are covered in the
          <a href="#collective">Collective Issues in Privacy</a> section.
        </p>
        <p>
          A <dfn>vulnerable person</dfn> is a [=person=] who, at least in the [=context=] of
          the [=processing=] being discussed, are unable to exercise sufficient
          self-determination for any consent they may provide to be receivable. This includes for
          example children, employees with respect to their employers, people in some situations of
          intellectual or psychological impairment, or refugees.
        </p>
      </section>
      <section>
        <h2>The Parties</h2>
        <p>
          A <dfn>party</dfn> is a [=person=], a legal entity, or a set of legal entities that
          share common owners, common controllers, and a group identity that is readily evident to
          the [=user=] without them needing to consult additional material, typically through
          common branding.
        </p>
        <p>
          The <dfn data-lt="first parties">first party</dfn> is a [=party=] with which the [=user=] intends to
          interact. Merely hovering over, muting, pausing, or closing a given piece of content does
          not constitute a [=user=]'s intent to interact with another party, nor does the simple
          fact of loading a [=party=] embedded in the one with which the user intends to
          interact. In cases of clear and conspicuous joint branding, there can be multiple [=first
          parties=]. The [=first party=] is necessarily a [=data controller=] of the data processing
          that takes places as a consequence of a [=user=] interacting with it.
        </p>
        <p>
          A <dfn data-lt="third parties">third party</dfn> is any [=party=] other than the [=user=],
          the [=first party=], or a [=service provider=] acting on behalf of either the [=user=] or
          the [=first party=].
        </p>
        <p>
          A <dfn>service provider</dfn> or <dfn>data processor</dfn> is considered to be the same
          [=party=] as the entity contracting it to perform the relevant [=processing=] if it:
        </p>
        <ul>
          <li>
            is processing the data on behalf of that [=party=];
          </li>
          <li>
            ensures that the data is only retained, accessed, and used as directed by that [=party=]
            and solely for the list of explicitly-specified [=purposes=] detailed by the directing
            [=party=] or [=data controller=];
          </li>
          <li>
            may determine implementation details of the data processing in question but does not
            determine the [=purpose=] for which the data is being [=processed=] nor the overarching
            [=means=] through which the [=purpose=] is carried out;
          </li>
          <li>
            has no independent right to use the data other than in a [=permanently de-identified=]
            form (e.g., for monitoring service integrity, load balancing, capacity planning, or
            billing); and,
          </li>
          <li>
            has a contract in place with the [=party=] which is consistent with the above limitations.
          </li>
        </ul>
        <p>
          A <dfn>data controller</dfn> is an entity that determines the [=means=] and [=purposes=]
          of data processing. Any party that is not a [=service provider=] is a [=data controller=].
        </p>
        <p>
          The <dfn>Vegas Rule</dfn> is a simple implementation of privacy in which "<em>what happens
          with the [=first party=] stays with the [=first party=]</em>." Put differently, it
          describes a situation in which the [=first party=] is the only [=data controller=].
        </p>
      </section>
      <section>
        <h2>Acting on Data</h2>
        <p>
          A [=party=] <dfn data-lt="process|processing|processed|data processing">processes</dfn> data if it
          carries out operations on [=personal data=], whether or not by automated means, such as
          collection, recording, organisation, structuring, storage, adaptation or alteration,
          retrieval, consultation, use, disclosure by transmission, [=sharing=], dissemination or
          otherwise making available, [=selling=], alignment or combination, restriction, erasure or
          destruction.
        </p>
        <p>
          A [=party=] <dfn data-lt="share|sharing">shares</dfn> data if it provides it to any other
          [=party=]. Note that this definition allows a [=party=] to provide that data to its own
          [=service providers=].
        </p>
        <p>
          A [=party=] <dfn data-lt="sell|selling">sells</dfn> data when it [=shares=] it in exchange
          for consideration, monetary or otherwise.
        </p>
      </section>
      <section>
        <h2>Contexts and Privacy</h2>
        <p>
          The <dfn>purpose</dfn> of a given [=processing=] of data is an anticipated, intended, or
          planned outcome of this [=processing=] which is achieved or aimed for within a given
          [=context=]. A [=purpose=], when described, should be specific enough to be actionable by
          someone familiar with the relevant [=context=] (ie. they could independently determine
          [=means=] that reasonably correspond to those being effectively deployed).
        </p>
        <p>
          The <dfn>means</dfn> are the general method of [=data processing=] through which a given
          [=purpose=] is implemented, in a given [=context=], considered at a relatively abstract
          level and not necessarily all the way down to implementation details. Example:
          <em>the user will have their preferences restored (purpose) by looking up their identifier
          in a preferences store (means)</em>.
        </p>
        <p>
          A <dfn>context</dfn> is a physical or digital environment that a [=person=] interacts with
          for a purpose of their own (that they typically share with other [=person=] who interact
          with the same environment).
        </p>
        <p>
          A [=context=] can be further described through:
        </p>
        <ul>
          <li>
            Its <dfn>actors</dfn>, which comprise the <dfn>subject</dfn> (a [=person=]) as well as
            the <dfn>sender</dfn> and <dfn>recipient</dfn> of the data (which are [=parties=]).
          </li>
          <li>
            Its <dfn>attributes</dfn>, which are the types of [=personal data=] being [=processed=]
            in the [=context=].
          </li>
          <li>
            Its <dfn>transmission principles</dfn>, which are the constraints (typically technical
            or legal) being placed upon the [=data processing=].
          </li>
        </ul>
        <p>
          A [=context=] carries <dfn>context-relative informational norms</dfn> that determine
          whether a given [=data processing=] is <dfn>appropriate</dfn> (if the norms are adhered to)
          or <dfn>inappropriate</dfn> (when the norms are violated). A norm violation can be for
          instance the exfiltration of [=personal data=] from a context or the lack of respect for
          [=transmission princples=].
        </p>
        <p>
          We define <dfn>privacy</dfn> as a right to [=appropriate=] [=data processing=]. A
          <dfn>privacy violation</dfn> is, correspondingly, [=inappropriate=] [=data processing=]
          [[PRIVACY-IN-CONTEXT]].
        </p>
        <p>
          Note that a [=first party=] can be comprised of multiple [=contexts=] if it is large
          enough that [=persons=] would interact with it for more than one [=purpose=]. [=Sharing=]
          [=personal data=] across [=contexts=] is, in the overwhelming majority of cases,
          [=inappropriate=].
        </p>
        <div class="example">
          <p>
            Your cute little pup uses <em>Poodle Naps</em> to find comfortable places to snooze,
            and <em>Poodle Fetch</em> to locate the best sticks. Napping and fetching are different
            [=contexts=] with different norms, and sharing data between these contexts is a
            [=privacy violation=] despite the shared ownership of <em>Naps</em> and <em>Fetch</em>
            by the <em>Poodle</em> conglomerate.
          </p>
        </div>
        <p>
          Additionally, <dfn data-lt="privacy-labor">privacy labour</dfn> is the practice of having
          a [=person=] carry out the work of ensuring [=data processing=] of which they are the
          subject is [=appropriate=], instead of having the [=parties=] be responsible for that
          work as is more respectable.
        </p>
      </section>
      <section>
        <h2>User Agents</h2>
        <p>
          Tk
        </p>
        <!--
          - user agent (distinct from the parties)
            - the UA is not a context, collecting data from the UA beyond basic privacy-preserving
              telemetry to inform product design and the future of the Web is a violation of privacy
              (unless there is reliable multistakeholder governance over the collection to confer it
              a form of democratic legitimity)
          - fiduciary
          - self-dealing
          - care
            - the difference between care and data paternalism is that the latter purports to help
              in part by removing agency ("don't worry about it, so long as your data is with us
              it's safe, you don't need to know what we do with it, it's all good because we're
              good people") whereas care aims to support people by enhancing their agency and
              sovereignty
          - honesty
          - loyalty
          - protection & data protection
        -->
      </section>
    </section>
    <section>
      <h2>Privacy Threat Model Methodology</h2>
      <p>
        Tk
      </p>
      <!--
        - explain the difference with security: all the parties other than the user are threats,
          including the first party (first and foremost) and the user agent
        - defining a context
        - respecting contextual integrity
      -->
    </section>
    <section>
      <h2>User Control and Autonomy</h2>
      <p>
        We need to start from a simple yet salient point: in today's data economy, informational
        self-determination is impossible. It is crucially not to confuse this fact, as others have
        before, with the contention that privacy is dead.
      </p>
      <!--
        - increased choice is not increased autonomy
          - Acquisti on influence over privacy preferences
          - this is a good use of the Agnes Transparency & Choice meme
        - opt in, opt out, consent: a comparison
          - consent is bad for vulnerable subjects because it incentivises companies to NOT know
            that a given subject is vulnerable, in order not to be liable for it
          - outcomes versus means: increasing agency versus notice & choice
          - consent is comparable to the general problem of permissions on the Web platform. In the
            same way that it should be clear when a given device capability is in use (eg. you are
            providing geolocation or camera access), sharing data should be set up in such a way
            that it requires deliberate, specific action from the user (eg. triggering a form
            control) and if that consent is persistent, there should be an indicator that data is
            being transmitted shown at all times, in such a way that the user can easily swich it
            off. In general, providing consent should be rare, difficult, highly intensional, and
            temporary
        - FIPs
          - quick summary of the FIPs, mention RelTurn and the killer Barrett quote, great if you're
            partying with data like it's 1972.
          - the FIPs put all the load on self-determination and therefore do not forbid specific
            types of data processing, they only place them under different procedural requirements.
          - one problem with procedural approaches to privacy is that they place the same
            requirements in situations where the parties operate under huge asymmetries of power
            ‚Äî for instance the user of an essential service provided by a monopolistic platform ‚Äî
            and parties that are very much on equal footing, or even where the data subject may have
            greater power, as is the case with small businesses operating in a competitive
            environment. It further does not consider cases in which one business may coerce other
            businesses into facilitating its extractive practices, as is often the case with
            dominant players in advertising or in content aggregation [[CAT]].
        - explain that there is no value in asking users about technical methods (eg. cookies) but
          only ever about purposes
        - the value in global opt outs
          - rectify automation asymmetry
          - essentially like having a robot click or convey opt out automatically for the user
          - understanding global opt outs under consent regimes such as the GDPR
            - the GOO essentially conveys a preference for state, not for transition, so it will
              opt you out if you ever are opted in
        - dark patterns
        - tiered models by context defined in standards
          - define legitimate interest based on CI. LI tends to be understood as "what we can get
            away with without having to rely on consent" instead of what legitimately matches the
            expectations and interests of both parties in a relationship. Add some relational, some
            fiduciary values to support it. In fact, LI could be grounded entirely in fiduciary
            values as expressed by Hartzog.
      -->
    </section>
    <section>
      <h2>Identity on the Web</h2>
      <p>
        Tk
      </p>
      <!--
        - only the most powerful can afford to have the same identity across contexts without
          adverse consequences. Identity is by nature fragmented, and UAs must work in support of
          users having different identifies in every context and to prevent their recognition.
          The more vulnerable one is, the more important it is to fragment identities, supporting
          recognition across contexts is oppressive as it forces vulnerability into the open. UAs
          should actively prevent identification across contexts, including across their vendors.
        - Each context should be an identity fragmentainer.
        - lift MOI from RHEA
      -->
    </section>
    <section id="collective">
      <h2>Collective Issues in Privacy</h2>
      <p>
        Tk
      </p>
      <!--
        - legibility
        - data protection is all about the data, maybe it should be more about the people [[REL-TURN]]
        - the FIPs were designed for an area of databases, not for the data market and the data
          industrial complex. Individual privacy harms exist [[CITRON-SOLOVE]] but the collective
          aspects need focus too.
        - data can be used to decide what we see and what we prefer
          - "To govern is to make believe." ‚ÄîMachiavelli
        - second-wave colonisation: extractive practices with respect to countries that do not have
          significant data industrial presence
        - data markets, differential valuation, rivalrous + non-exludable
          - Acquisti 2014
          - Stucke 2017
          - Binns 2018

        - The "relational turn" considers the relation between the people who expose themselves and
          the entities that invite that disclosure. It's about power. One key understanding here is
          that, unlike traditional data protection, this relation persists even when data is
          anonymised since power can stem from an excessive, asymmetric understanding of cohorts.
          This is why data derived from individual data must itself be governed in some cases
          (which we need to define), even if deidentified. What makes an understanding excessive?
          That is a question for agency that might not entirely fit here.
        - Collective issues in data require collective solutions. The proper goal of data governance
          at the standards-setting level is the provision of institutions that can handle
          population-level problems in data, and it might not necessarily do so by increasing
          individual control over data.
        - mention Garuda as the outline of potential legitimate governance over data
        - Imagine a case in which collecting browser data can be leveraged to improve both search
          services (which have a business model) and user security (which generally doesn't). This
          data could be collected through a data trust under stakeholder governance, search
          companies paying for access with strong checks and balances, and privacy guarantees, and
          the funds would be used to support enhanced security for all.
      -->
    </section>
  </body>
</html>
